// Book sales data utilities

import { createClient } from '@/lib/supabase'
import { BookSalesData, BookSalesFileInfo, BookTrend, PublisherStats, CategoryStats, DailySalesOverview } from '@/types/book-sales'
import {
  isDummyMode,
  loadDummyBookSalesData,
  getDummyBookSalesFiles,
  generateDummyBookData
} from '@/lib/dummy-book-data'

const isProductionMode = () => !isDummyMode()

// ê°œë°œ ëª¨ë“œìš© ê°€ì§œ ì°¨íŠ¸ ë°ì´í„° ìƒì„± í•¨ìˆ˜ - fake_isbn ê¸°ë°˜
const generateDummyChartDataForBooks = (
  selectedBooks: { title: string; fakeIsbn: string }[],
  daysBefore: number,
  progressCallback?: (progress: number, status: string) => void
): any[] => {
  const data = []
  const today = new Date()

  // ì§„í–‰ë¥  ì‹œë®¬ë ˆì´ì…˜
  progressCallback?.(10, 'ê°€ì§œ ë°ì´í„° ìƒì„± ì¤€ë¹„ ì¤‘...')
  setTimeout(() => progressCallback?.(30, 'ê°€ì§œ ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...'), 100)

  for (let i = daysBefore - 1; i >= 0; i--) {
    const date = new Date(today)
    date.setDate(today.getDate() - i)
    const dateString = date.toISOString().split('T')[0]

    const entry: any = { date: dateString }

    selectedBooks.forEach((book, index) => {
      // fake_isbnì´ ìœ íš¨í•œì§€ í™•ì¸
      if (!book.fakeIsbn || !book.title) {
        console.warn(`âš ï¸ Invalid book data:`, book)
        return
      }

      const fakeIsbn = book.fakeIsbn
      const baseValue = 500 + (index * 100) // ê° ë„ì„œë³„ ê¸°ë³¸ íŒë§¤ì§€ìˆ˜
      const variation = Math.random() * 200 - 100 // -100 ~ +100 ë²”ìœ„ì˜ ë³€ë™
      const salesPoint = Math.max(50, Math.round(baseValue + variation))

      // fake_isbnì„ í‚¤ë¡œ ì‚¬ìš©
      entry[fakeIsbn] = salesPoint
      entry[`${fakeIsbn}_rank`] = Math.floor(Math.random() * 100) + 1 // 1~100ìœ„ ëœë¤

    })

    data.push(entry)
  }

  setTimeout(() => {
    progressCallback?.(100, `ê°€ì§œ ë°ì´í„° ìƒì„± ì™„ë£Œ! ${data.length}ê°œ ë°ì´í„° í¬ì¸íŠ¸`)
  }, 200)

  return data
}

// Get list of available data files from Supabase Storage
export const getBookSalesFiles = async (): Promise<BookSalesFileInfo[]> => {
  // ë”ë¯¸ ëª¨ë“œì¸ ê²½ìš° ë”ë¯¸ ë°ì´í„° ë°˜í™˜
  if (isDummyMode()) {
    return getDummyBookSalesFiles()
  }
  
  try {
    const supabase = createClient()
    
    // List all files in the book-sales-data bucket
    const { data: files, error } = await supabase.storage
      .from('book-sales-data')
      .list('', {
        limit: 500,
        offset: 0,
        sortBy: { column: 'name', order: 'asc' }
      })

    if (error) {
      console.error('Error fetching files from Supabase Storage:', error)
      return []
    }

    // Filter and parse JSON files with yes24_ pattern
    const bookSalesFiles: BookSalesFileInfo[] = []
    
    for (const file of files || []) {
      if (file.name.startsWith('yes24_') && file.name.endsWith('.json')) {
        try {
          // Parse filename: yes24_2025_MMDD.json
          const nameWithoutExt = file.name.replace('.json', '')
          const parts = nameWithoutExt.split('_') // ['yes24', '2025', 'MMDD']
          
          if (parts.length === 3) {
            const year = parts[1]
            const monthDay = parts[2]
            
            if (monthDay.length === 4) {
              const month = monthDay.substring(0, 2)
              const day = monthDay.substring(2, 4)
              const date = `${year}-${month}-${day}`
              
              bookSalesFiles.push({
                date,
                filename: file.name,
                displayDate: `${year}ë…„ ${parseInt(month)}ì›” ${parseInt(day)}ì¼`
              })
            }
          }
        } catch (parseError) {
          console.warn(`Failed to parse filename: ${file.name}`, parseError)
        }
      }
    }
    
    // Sort by date
    return bookSalesFiles.sort((a, b) => new Date(a.date).getTime() - new Date(b.date).getTime())
  } catch (error) {
    console.error('Error in getBookSalesFiles:', error)
    return []
  }
}

// Load book sales data for a specific date from Supabase Storage
export const loadBookSalesData = async (filename: string): Promise<BookSalesData> => {
  // ë”ë¯¸ ëª¨ë“œì¸ ê²½ìš° ë”ë¯¸ ë°ì´í„° ë°˜í™˜
  if (isDummyMode()) {
    return loadDummyBookSalesData(filename)
  }
  
  try {
    const supabase = createClient()
    
    // Download file from Supabase Storage
    const { data, error } = await supabase.storage
      .from('book-sales-data')
      .download(filename)

    if (error) {
      console.error(`Error downloading ${filename}:`, error)
      return {}
    }

    // Convert blob to text and parse JSON
    const text = await data.text()
    const jsonData = JSON.parse(text)
    return jsonData
  } catch (error) {
    console.error(`Error loading book sales data:`, error)
    return {}
  }
}

// Load multiple files and combine data
export const loadMultipleBookSalesData = async (filenames: string[]): Promise<{[date: string]: BookSalesData}> => {
  const results: {[date: string]: BookSalesData} = {}
  
  // ë”ë¯¸ ëª¨ë“œì¸ ê²½ìš° ë”ë¯¸ ë°ì´í„° ë°˜í™˜
  if (isDummyMode()) {
    for (const filename of filenames) {
      const nameWithoutExt = filename.replace('yes24_', '').replace('.json', '')
      const parts = nameWithoutExt.split('_')
      
      if (parts.length === 2) {
        const year = parts[0]
        const monthDay = parts[1]
        
        if (monthDay.length === 4) {
          const month = monthDay.substring(0, 2)
          const day = monthDay.substring(2, 4)
          const date = `${year}-${month}-${day}`
          
          results[date] = generateDummyBookData(100)
        }
      }
    }
    
    return results
  }
  
  for (const filename of filenames) {
    // yes24_2025_MMDD.json â†’ 2025-MM-DD
    const nameWithoutExt = filename.replace('yes24_', '').replace('.json', '')
    const parts = nameWithoutExt.split('_') // ['2025', 'MMDD']
    
    if (parts.length === 2) {
      const year = parts[0]
      const monthDay = parts[1]
      
      if (monthDay.length === 4) {
        const month = monthDay.substring(0, 2)
        const day = monthDay.substring(2, 4)
        const formattedDate = `${year}-${month}-${day}`
        
        results[formattedDate] = await loadBookSalesData(filename)
      }
    }
  }
  
  return results
}

// Analyze book trends across multiple dates
export const analyzeBookTrends = (multiData: {[date: string]: BookSalesData}): BookTrend[] => {
  const bookTrends: {[isbn: string]: BookTrend} = {}
  
  Object.entries(multiData).forEach(([date, data]) => {
    Object.entries(data).forEach(([bookId, bookInfo]) => {
      const isbn = bookInfo.fake_isbn.toString()
      
      if (!bookTrends[isbn]) {
        bookTrends[isbn] = {
          bookId: bookId,
          title: bookInfo.title,
          dates: [],
          ranks: [],
          salesPoints: [],
          priceChanges: []
        }
      }
      
      bookTrends[isbn].dates.push(date)
      bookTrends[isbn].ranks.push(bookInfo.rank)
      bookTrends[isbn].salesPoints.push(bookInfo.sales_point)
      bookTrends[isbn].priceChanges.push(bookInfo.right_price)
    })
  })
  
  return Object.values(bookTrends).filter(trend => trend.dates.length > 1)
}

// Get publisher statistics
export const getPublisherStats = (data: BookSalesData): PublisherStats[] => {
  const publisherMap: {[key: string]: {books: any[], totalSales: number, totalRanks: number, totalPrices: number}} = {}
  
  Object.values(data).forEach(book => {
    if (!publisherMap[book.publisher]) {
      publisherMap[book.publisher] = {
        books: [],
        totalSales: 0,
        totalRanks: 0,
        totalPrices: 0
      }
    }
    
    publisherMap[book.publisher].books.push(book)
    publisherMap[book.publisher].totalSales += book.sales_point
    publisherMap[book.publisher].totalRanks += book.rank
    publisherMap[book.publisher].totalPrices += book.right_price
  })
  
  return Object.entries(publisherMap).map(([publisher, stats]) => ({
    name: publisher,
    bookCount: stats.books.length,
    totalSalesPoints: stats.totalSales,
    averageRank: Math.round(stats.totalRanks / stats.books.length),
    averagePrice: Math.round(stats.totalPrices / stats.books.length)
  })).sort((a, b) => b.totalSalesPoints - a.totalSalesPoints)
}

// Get category statistics
export const getCategoryStats = (data: BookSalesData): CategoryStats[] => {
  const categoryMap: {[key: string]: {books: any[], totalSales: number}} = {}
  
  Object.values(data).forEach(book => {
    // Use first tag as primary category
    const category = book.tags[0] || 'Unknown'
    
    if (!categoryMap[category]) {
      categoryMap[category] = {
        books: [],
        totalSales: 0
      }
    }
    
    categoryMap[category].books.push(book)
    categoryMap[category].totalSales += book.sales_point
  })
  
  return Object.entries(categoryMap).map(([category, stats]) => ({
    category,
    bookCount: stats.books.length,
    totalSalesPoints: stats.totalSales,
    topBooks: stats.books
      .sort((a, b) => b.sales_point - a.sales_point)
      .slice(0, 3)
      .map(book => ({title: book.title, salesPoint: book.sales_point}))
  })).sort((a, b) => b.totalSalesPoints - a.totalSalesPoints)
}

// Get daily sales overview
export const getDailySalesOverview = (data: BookSalesData, date: string): DailySalesOverview => {
  const books = Object.values(data)
  const totalSalesPoints = books.reduce((sum, book) => sum + book.sales_point, 0)
  const averageRank = books.reduce((sum, book) => sum + book.rank, 0) / books.length
  const topBook = books.reduce((top, book) => book.sales_point > top.sales_point ? book : top, books[0])
  const publishers = new Set(books.map(book => book.publisher))
  
  return {
    date,
    totalBooks: books.length,
    totalSalesPoints,
    averageRank: Math.round(averageRank),
    topBook: {
      title: topBook.title,
      rank: topBook.rank,
      salesPoint: topBook.sales_point,
      publisher: topBook.publisher
    },
    publisherCount: publishers.size
  }
}

// Search books by title, author, or publisher
export const searchBooks = (data: BookSalesData, searchTerm: string) => {
  const term = searchTerm.toLowerCase()
  
  return Object.entries(data).filter(([_, book]) => 
    book.title.toLowerCase().includes(term) ||
    book.author.some(author => author.toLowerCase().includes(term)) ||
    book.publisher.toLowerCase().includes(term)
  ).map(([bookId, book]) => ({ bookId, ...book }))
}

// Filter books by price range
export const filterBooksByPriceRange = (data: BookSalesData, minPrice: number, maxPrice: number) => {
  return Object.entries(data).filter(([_, book]) => 
    book.right_price >= minPrice && book.right_price <= maxPrice
  ).map(([bookId, book]) => ({ bookId, ...book }))
}

// Get top books by sales point
export const getTopBooksBySales = (data: BookSalesData, limit: number = 10) => {
  return Object.entries(data)
    .map(([bookId, book]) => ({ bookId, ...book }))
    .sort((a, b) => b.sales_point - a.sales_point)
    .slice(0, limit)
}

// Get books by rank range
export const getBooksByRankRange = (data: BookSalesData, minRank: number, maxRank: number) => {
  return Object.entries(data)
    .filter(([_, book]) => book.rank >= minRank && book.rank <= maxRank)
    .map(([bookId, book]) => ({ bookId, ...book }))
    .sort((a, b) => a.rank - b.rank)
}

// Get files within date range (days before today)
export const getFilesInDateRange = async (daysBefore: number): Promise<BookSalesFileInfo[]> => {
  try {
    const allFiles = await getBookSalesFiles()
    const today = new Date()
    const targetDate = new Date(today)
    targetDate.setDate(today.getDate() - daysBefore)
    
    return allFiles.filter(file => {
      const fileDate = new Date(file.date)
      return fileDate >= targetDate && fileDate <= today
    }).sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime()) // ìµœì‹  ìˆœ ì •ë ¬
  } catch (error) {
    console.error('Error getting files in date range:', error)
    return []
  }
}

// Load data for specific period (30, 60, 90, 120 days)
export const loadDataForPeriod = async (daysBefore: number): Promise<{[date: string]: BookSalesData}> => {
  try {
    const filesInRange = await getFilesInDateRange(daysBefore)
    const filenames = filesInRange.map(f => f.filename)
    
    return await loadMultipleBookSalesData(filenames)
  } catch (error) {
    console.error(`Error loading data for ${daysBefore} days:`, error)
    return {}
  }
}

// Calculate period overview statistics
export const getPeriodOverview = (periodData: {[date: string]: BookSalesData}) => {
  let totalSalesPoints = 0
  const publisherSalesMap: {[publisher: string]: number} = {}
  let totalDays = 0
  
  Object.values(periodData).forEach(dailyData => {
    if (Object.keys(dailyData).length > 0) {
      totalDays++
      Object.values(dailyData).forEach(book => {
        totalSalesPoints += book.sales_point
        publisherSalesMap[book.publisher] = (publisherSalesMap[book.publisher] || 0) + book.sales_point
      })
    }
  })
  
  // Top 10 publishers by sales points
  const topPublishers = Object.entries(publisherSalesMap)
    .map(([publisher, salesPoints]) => ({ publisher, salesPoints }))
    .sort((a, b) => b.salesPoints - a.salesPoints)
    .slice(0, 10)
  
  return {
    totalDays,
    totalSalesPoints,
    topPublishers,
    averageDailySales: totalDays > 0 ? Math.round(totalSalesPoints / totalDays) : 0,
    publisherCount: Object.keys(publisherSalesMap).length
  }
}

// Get aggregated publisher stats for period
export const getPublisherStatsForPeriod = (periodData: {[date: string]: BookSalesData}) => {
  const publisherMap: {[key: string]: {
    totalSales: number, 
    bookCount: number, 
    totalPrices: number,
    totalRanks: number,
    books: Set<string> // ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ Set
  }} = {}
  
  Object.values(periodData).forEach(dailyData => {
    Object.values(dailyData).forEach(book => {
      if (!publisherMap[book.publisher]) {
        publisherMap[book.publisher] = {
          totalSales: 0,
          bookCount: 0,
          totalPrices: 0,
          totalRanks: 0,
          books: new Set()
        }
      }
      
      publisherMap[book.publisher].totalSales += book.sales_point
      publisherMap[book.publisher].totalPrices += book.right_price
      publisherMap[book.publisher].totalRanks += book.rank
      publisherMap[book.publisher].books.add(book.title) // ë„ì„œëª…ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
    })
  })
  
  return Object.entries(publisherMap).map(([publisher, stats]) => ({
    name: publisher,
    bookCount: stats.books.size, // ì‹¤ì œ ìœ ë‹ˆí¬ ë„ì„œ ìˆ˜
    totalSalesPoints: stats.totalSales,
    averagePrice: stats.books.size > 0 ? Math.round(stats.totalPrices / stats.books.size) : 0,
    averageRank: stats.books.size > 0 ? Math.round(stats.totalRanks / stats.books.size) : 0
  })).sort((a, b) => b.totalSalesPoints - a.totalSalesPoints)
}

// Enhanced multi-tier caching system
const fileCache = new Map<string, BookSalesData>()
const chartDataCache = new Map<string, any[]>()
const aggregatedDataCache = new Map<string, any>()

const CACHE_SIZE_LIMIT = 200 // Increased memory cache limit
const CHART_CACHE_SIZE_LIMIT = 50 // Chart-specific cache
const AGGREGATED_CACHE_SIZE_LIMIT = 100 // Aggregated data cache

// LocalStorage persistent cache with versioning
const STORAGE_KEY_PREFIX = 'book_sales_cache_'
const CHART_STORAGE_KEY_PREFIX = 'chart_data_cache_'
const STORAGE_VERSION = 'v2' // Version bump for new cache structure
const MAX_STORAGE_AGE = 48 * 60 * 60 * 1000 // Extended to 48 hours

interface CacheEntry {
  data: BookSalesData
  timestamp: number
  version: string
}

interface ChartDataCacheEntry {
  data: any[]
  timestamp: number
  version: string
  bookTitles: string[]
  daysBefore: number
}

// LocalStorage cache utilities
const getFromStorage = (filename: string): BookSalesData | undefined => {
  try {
    const key = STORAGE_KEY_PREFIX + filename
    const stored = localStorage.getItem(key)
    if (!stored) return undefined

    const entry: CacheEntry = JSON.parse(stored)
    
    // Check version and age
    if (entry.version !== STORAGE_VERSION || 
        Date.now() - entry.timestamp > MAX_STORAGE_AGE) {
      localStorage.removeItem(key)
      return undefined
    }

    return entry.data
  } catch (error) {
    console.warn(`Cache read error for ${filename}:`, error)
    return undefined
  }
}

const saveToStorage = (filename: string, data: BookSalesData): void => {
  try {
    const key = STORAGE_KEY_PREFIX + filename
    const entry: CacheEntry = {
      data,
      timestamp: Date.now(),
      version: STORAGE_VERSION
    }
    
    localStorage.setItem(key, JSON.stringify(entry))
  } catch (error) {
    // Storage full or other error - silently fail
    console.warn(`Cache write error for ${filename}:`, error)
    // Try to clear some old entries
    clearOldCacheEntries()
  }
}

const clearOldCacheEntries = (): void => {
  try {
    const keys = Object.keys(localStorage).filter(key => 
      key.startsWith(STORAGE_KEY_PREFIX) || key.startsWith(CHART_STORAGE_KEY_PREFIX))
    const now = Date.now()
    
    keys.forEach(key => {
      try {
        const stored = localStorage.getItem(key)
        if (stored) {
          const entry: CacheEntry | ChartDataCacheEntry = JSON.parse(stored)
          if (now - entry.timestamp > MAX_STORAGE_AGE || entry.version !== STORAGE_VERSION) {
            localStorage.removeItem(key)
          }
        }
      } catch {
        localStorage.removeItem(key) // Remove corrupted entries
      }
    })
  } catch (error) {
    console.warn('Error clearing old cache entries:', error)
  }
}

// Chart data cache utilities
const getChartDataFromCache = (bookTitles: string[], daysBefore: number): any[] | undefined => {
  try {
    // Create a cache key based on sorted book titles and period
    const sortedTitles = [...bookTitles].sort()
    const cacheKey = `${sortedTitles.join('|')}:${daysBefore}`
    
    // Check memory cache first
    const memoryData = chartDataCache.get(cacheKey)
    if (memoryData) {
      return memoryData
    }
    
    // Check localStorage cache
    const storageKey = CHART_STORAGE_KEY_PREFIX + cacheKey
    const stored = localStorage.getItem(storageKey)
    if (!stored) return undefined

    const entry: ChartDataCacheEntry = JSON.parse(stored)
    
    // Check version and age
    if (entry.version !== STORAGE_VERSION || 
        Date.now() - entry.timestamp > MAX_STORAGE_AGE) {
      localStorage.removeItem(storageKey)
      return undefined
    }
    
    // Verify cache validity by checking if parameters match
    if (entry.daysBefore !== daysBefore || 
        entry.bookTitles.length !== bookTitles.length ||
        !entry.bookTitles.every(title => bookTitles.includes(title))) {
      return undefined
    }

    // Add to memory cache
    if (chartDataCache.size >= CHART_CACHE_SIZE_LIMIT) {
      const firstKey = chartDataCache.keys().next().value
      if (firstKey) {
        chartDataCache.delete(firstKey)
      }
    }
    chartDataCache.set(cacheKey, entry.data)

    return entry.data
  } catch (error) {
    console.warn('Chart cache read error:', error)
    return undefined
  }
}

const saveChartDataToCache = (bookTitles: string[], daysBefore: number, data: any[]): void => {
  try {
    const sortedTitles = [...bookTitles].sort()
    const cacheKey = `${sortedTitles.join('|')}:${daysBefore}`
    
    // Save to memory cache
    if (chartDataCache.size >= CHART_CACHE_SIZE_LIMIT) {
      const firstKey = chartDataCache.keys().next().value
      if (firstKey) {
        chartDataCache.delete(firstKey)
      }
    }
    chartDataCache.set(cacheKey, data)
    
    // Save to localStorage cache
    const storageKey = CHART_STORAGE_KEY_PREFIX + cacheKey
    const entry: ChartDataCacheEntry = {
      data,
      timestamp: Date.now(),
      version: STORAGE_VERSION,
      bookTitles: sortedTitles,
      daysBefore
    }
    
    localStorage.setItem(storageKey, JSON.stringify(entry))
  } catch (error) {
    console.warn('Chart cache write error:', error)
    clearOldCacheEntries()
  }
}

// Smart sampling algorithm for large date ranges
const getOptimalSampling = (totalFiles: number, daysBefore: number) => {
  // For periods > 90 days, use smart sampling to reduce load time
  if (daysBefore <= 60) return { sampleEvery: 1, maxPoints: totalFiles }
  if (daysBefore <= 120) return { sampleEvery: 2, maxPoints: 60 } 
  if (daysBefore <= 180) return { sampleEvery: 3, maxPoints: 60 }
  return { sampleEvery: 4, maxPoints: 45 } // Very long periods
}

// ê°œì„ ëœ ë¶ íƒ€ì´í‹€ ë§¤ì¹­ ì‹œìŠ¤í…œ
const createBookMatcher = (bookTitles: string[]) => {
  // ì•ˆì „í•œ í‚¤ ìƒì„± í•¨ìˆ˜
  const createSafeKey = (title: string) => {
    // ê¸¸ì´ ì œí•œ (ìµœëŒ€ 50ì)
    let safeTitle = title.length > 50 ? title.substring(0, 50).trim() : title
    
    // íŠ¹ìˆ˜ë¬¸ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ì)
    safeTitle = safeTitle.replace(/[^\w\sã„±-ã…ã…-ã…£ê°€-í£()[\].,!?:-]/g, '')
    
    return safeTitle.trim() || title.substring(0, 20) // ë¹ˆ ë¬¸ìì—´ ë°©ì§€
  }

  const matchers = bookTitles.map(title => {
    const safeKey = createSafeKey(title)
    return {
      originalTitle: title,
      safeKey: safeKey,
      searchKey: title.substring(0, 30) // ê²€ìƒ‰ìš© ì§§ì€ í‚¤
    }
  })
  
  return {
    // ë§¤ì¹­ëœ ì•ˆì „í•œ í‚¤ ë°˜í™˜
    getSafeKey: (bookTitle: string) => {
      // 1. ì •í™•í•œ ë§¤ì¹­
      let matcher = matchers.find(m => m.originalTitle === bookTitle)
      if (matcher) return matcher.safeKey
      
      // 2. ë¶€ë¶„ ë§¤ì¹­ (ì• 30ì)
      const searchKey = bookTitle.substring(0, 30)
      matcher = matchers.find(m => 
        m.searchKey.includes(searchKey) || 
        searchKey.includes(m.searchKey)
      )
      if (matcher) return matcher.safeKey
      
      // 3. í¬í•¨ ê´€ê³„ ë§¤ì¹­
      matcher = matchers.find(m => 
        bookTitle.includes(m.originalTitle) || 
        m.originalTitle.includes(bookTitle)
      )
      
      return matcher ? matcher.safeKey : null
    },
    
    // ë””ë²„ê¹…ì„ ìœ„í•œ ë§¤ì¹­ ì •ë³´
    getMatchingInfo: () => {
      return matchers.map(m => ({
        original: m.originalTitle,
        safe: m.safeKey,
        search: m.searchKey
      }))
    }
  }
}

// Progress callback interface
interface ProgressCallback {
  (progress: number, status: string): void
}

// fake_isbn ê¸°ë°˜ìœ¼ë¡œ ë„ì„œë¥¼ ë§¤ì¹­í•˜ëŠ” ì°¨íŠ¸ ë°ì´í„° ë¡œë”©
export const loadChartDataForBooks = async (
  selectedBooks: { title: string; fakeIsbn: string }[],
  daysBefore: number,
  availableFiles: BookSalesFileInfo[],
  progressCallback?: ProgressCallback
): Promise<any[]> => {
  try {
    // ê°œë°œ ëª¨ë“œì—ì„œëŠ” í•­ìƒ ê°€ì§œ ë°ì´í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
    if (isDummyMode()) {
      progressCallback?.(5, 'ê°œë°œ ëª¨ë“œ: ê°€ì§œ ë°ì´í„° ìƒì„± ì¤‘...')
      await new Promise(resolve => setTimeout(resolve, 500))

      const dummyData = generateDummyChartDataForBooks(selectedBooks, daysBefore, progressCallback)

      // ë”ë¯¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìµœì†Œí•œì˜ ë°ì´í„°ë¼ë„ ìƒì„±
      if (dummyData.length === 0 && selectedBooks.length > 0) {
        const fallbackData = [{
          date: new Date().toISOString().split('T')[0],
          ...selectedBooks.reduce((acc, book, index) => {
            if (book.fakeIsbn && book.title) {
              acc[book.fakeIsbn] = 100 + (index * 50)
              acc[`${book.fakeIsbn}_rank`] = index + 1
            }
            return acc
          }, {} as any)
        }]
        return fallbackData
      }

      return dummyData
    }

    // ğŸš€ Enhanced caching: ì´ì „ í˜•ì‹ ìºì‹œ ë¬´íš¨í™” í›„ ìƒˆë¡œ ìƒì„±
    progressCallback?.(5, 'ì´ì „ í˜•ì‹ ìºì‹œ ì‚­ì œ ë° ì‹ ê·œ ìƒì„±...')
    const fakeIsbns = selectedBooks.map(book => book.fakeIsbn)
    
    // ê¸°ì¡´ ìºì‹œ ëª¨ë‘ ì‚­ì œ (í˜•ì‹ ë³€ê²½ìœ¼ë¡œ ì¸í•œ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
    console.log('ğŸ—‘ï¸ ê¸°ì¡´ ì°¨íŠ¸ ìºì‹œ ì‚­ì œ ì¤‘... (fake_isbn í˜•ì‹ìœ¼ë¡œ ë³€ê²½ë¨)')
    chartDataCache.clear() // ë©”ëª¨ë¦¬ ìºì‹œ ì‚­ì œ
    
    // localStorage ìºì‹œë„ ì‚­ì œ
    try {
      Object.keys(localStorage).forEach(key => {
        if (key.startsWith(CHART_STORAGE_KEY_PREFIX)) {
          localStorage.removeItem(key)
        }
      })
    } catch (error) {
      console.warn('localStorage ìºì‹œ ì‚­ì œ ì‹¤íŒ¨:', error)
    }

    const today = new Date()
    const targetDate = new Date(today)
    targetDate.setDate(today.getDate() - daysBefore)

    // Filter and sort files by date
    let relevantFiles = availableFiles
      .filter(file => {
        const fileDate = new Date(file.date)
        return fileDate >= targetDate && fileDate <= today
      })
      .sort((a, b) => new Date(a.date).getTime() - new Date(b.date).getTime())

    // Apply smart sampling for large datasets
    const { sampleEvery, maxPoints } = getOptimalSampling(relevantFiles.length, daysBefore)
    if (sampleEvery > 1) {
      console.log(`ğŸ“Š Smart sampling: ${relevantFiles.length} files â†’ ${Math.ceil(relevantFiles.length / sampleEvery)} samples`)
      progressCallback?.(10, `ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§: ${relevantFiles.length}ê°œ íŒŒì¼ â†’ ${Math.ceil(relevantFiles.length / sampleEvery)}ê°œë¡œ ìµœì í™”`)
      relevantFiles = relevantFiles.filter((_, index) => index % sampleEvery === 0)
      relevantFiles = relevantFiles.slice(0, maxPoints) // Ensure we don't exceed maxPoints
    }

    console.log(`âš¡ Loading optimized chart data: ${relevantFiles.length} files over ${daysBefore} days`)
    progressCallback?.(15, `${relevantFiles.length}ê°œ íŒŒì¼ ë¡œë”© ì‹œì‘`)

    const chartDataMap: { [date: string]: any } = {}
    
    // fake_isbnì„ í‚¤ë¡œ í•˜ëŠ” ë„ì„œ ë§¤í•‘ ìƒì„±
    const isbnToBookMap = new Map<string, { title: string; fakeIsbn: string }>()
    selectedBooks.forEach(book => {
      isbnToBookMap.set(book.fakeIsbn, book)
    })
    
    console.log('ğŸ“š ë§¤ì¹­ ëŒ€ìƒ ë„ì„œ (fake_isbn ê¸°ë°˜):', Array.from(isbnToBookMap.entries()))

    // ğŸš€ Enhanced parallel processing with intelligent batch sizing
    const optimalBatchSize = Math.min(30, Math.max(8, Math.ceil(relevantFiles.length / 4))) // Larger batches for better performance
    const concurrentBatches = Math.min(3, Math.ceil(relevantFiles.length / 20)) // Process multiple batches concurrently
    
    progressCallback?.(20, `ê³ ì„±ëŠ¥ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: ${optimalBatchSize}, ë™ì‹œ ë°°ì¹˜: ${concurrentBatches})`)

    // ğŸš€ Process files in optimally sized concurrent batches
    const allBatches: BookSalesFileInfo[][] = []
    for (let i = 0; i < relevantFiles.length; i += optimalBatchSize) {
      allBatches.push(relevantFiles.slice(i, i + optimalBatchSize))
    }

    // Process all batches with enhanced parallel processing
    let filesProcessed = 0
    for (const batch of allBatches) {
      const batchPromises = batch.map(async file => {
        try {
          // 3-tier caching system
          let data = fileCache.get(file.filename)
          
          if (!data) {
            data = getFromStorage(file.filename)
            
            if (!data) {
              data = await loadBookSalesData(file.filename)
              saveToStorage(file.filename, data)
            }
            
            // Memory cache management with LRU
            if (fileCache.size >= CACHE_SIZE_LIMIT) {
              const firstKey = fileCache.keys().next().value
              if (firstKey) fileCache.delete(firstKey)
            }
            fileCache.set(file.filename, data)
          }

          const chartEntry: any = { date: file.date }
          let matchedCount = 0

          // fake_isbn ê¸°ë°˜ ë§¤ì¹­ ë¡œì§ - fake_isbnì„ ì§ì ‘ í‚¤ë¡œ ì‚¬ìš©
          Object.values(data).forEach((book: any) => {
            const bookFakeIsbn = book.fake_isbn?.toString()
            if (bookFakeIsbn && isbnToBookMap.has(bookFakeIsbn)) {
              // fake_isbnì„ ì§ì ‘ í‚¤ë¡œ ì‚¬ìš© (ì œëª©ì´ ì•„ë‹Œ)
              chartEntry[bookFakeIsbn] = book.sales_point
              chartEntry[`${bookFakeIsbn}_rank`] = book.rank
              matchedCount++
            }
          })

          // ë§¤ì¹­ ê²°ê³¼ ë¡œê¹…
          if (matchedCount > 0) {
            console.log(`ğŸ“ˆ ${file.date}: ${matchedCount}ê¶Œ ë§¤ì¹­ ì™„ë£Œ`)
          } else {
            console.warn(`âš ï¸ ${file.date}: ë§¤ì¹­ëœ ë„ì„œ ì—†ìŒ`)
            console.log('ğŸ“‹ í•´ë‹¹ ë‚ ì§œ ë„ì„œ fake_isbn ëª©ë¡:', 
              Object.values(data).slice(0, 5).map((book: any) => book.fake_isbn)
            )
          }

          return { date: file.date, entry: chartEntry }
        } catch (error) {
          console.warn(`âš ï¸ Failed to load ${file.filename}:`, error)
          return null
        }
      })

      const batchResults = await Promise.all(batchPromises)
      
      // Add successful results to chart data
      batchResults.forEach(result => {
        if (result) {
          chartDataMap[result.date] = result.entry
        }
      })

      // Enhanced progress tracking
      filesProcessed += batch.length
      const baseProgress = 20
      const batchProgress = Math.round((filesProcessed / relevantFiles.length) * 70)
      const totalProgress = baseProgress + batchProgress
      
      const cacheHitRate = Math.round((fileCache.size / Math.max(filesProcessed, 1)) * 100)
      progressCallback?.(totalProgress, `${filesProcessed}/${relevantFiles.length} íŒŒì¼ ì²˜ë¦¬ (ìºì‹œ ì ì¤‘ë¥ : ${cacheHitRate}%)`)
    }

    // Convert to sorted array
    progressCallback?.(95, 'ì°¨íŠ¸ ë°ì´í„° ì •ë ¬ ë° ìµœì í™” ì¤‘...')
    const sortedChartData = Object.values(chartDataMap).sort((a, b) => 
      new Date(a.date).getTime() - new Date(b.date).getTime()
    )

    // ğŸš€ Save to cache for future requests
    if (sortedChartData.length > 0) {
      saveChartDataToCache(fakeIsbns, daysBefore, sortedChartData)
    }

    progressCallback?.(100, `ì™„ë£Œ! ${sortedChartData.length}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ë¡œë”©`)
    return sortedChartData

  } catch (error) {
    console.error('âŒ Error loading chart data:', error)
    return []
  }
}